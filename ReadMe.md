# Gallstone Prediction from Clinical and Bioimpedance Data

**Predicting gallstone presence using non-invasive clinical, laboratory, and bioimpedance features** with a combination of classical machine learning and deep learning methods.  

This project demonstrates a full data science workflow, including exploratory data analysis, preprocessing, model training, evaluation, and interpretability, using **Python, scikit-learn and TensorFlow**.

---

## ğŸ“ Problem Statement

Gallstone disease is a common digestive disorder. Early prediction using non-invasive metrics such as bioimpedance, laboratory values, and patient demographics can improve patient outcomes and reduce the need for invasive diagnostics.  

**Goal:** Build models that predict gallstone presence from 38 clinical and bioimpedance features.

---

## ğŸ“‚ Dataset

- Source: [UCI Gallstone Dataset](https://www.kaggle.com/datasets/xixama/gallstone-dataset-uci)  
- Samples: 319 patients  
- Features:  
  - Clinical demographics: Age, Sex, BMI, Comorbidities  
  - Bioimpedance: TBW, ECW, ICW, Lean Mass, Fat Content, Visceral Fat, Bone Mass, etc.  
  - Laboratory: Glucose, Cholesterol, HDL, LDL, Triglycerides, AST, ALT, CRP, Vitamin D, etc.  
- Target: Gallstone presence (binary: 0 = present, 1 = absent)  

---

## ğŸ’¡ Project Workflow

1. **Exploratory Data Analysis (EDA)**  
   - Visualize distributions, correlations  
   - Identify patterns between features and target  

2. **Data Preprocessing**  
   - Handle missing values (none in this dataset)  
   - Standardize numerical features  
   - Encode categorical variables  
   - **Stratified train/test split** to preserve class balance  
   - **Stratified K-Fold cross-validation** for robust evaluation  

3. **Baseline Model: ElasticNet**  
   - Train linear model with L1/L2 regularization  
   - Hyperparameter tuning via cross-validation  
   - Evaluate metrics: Accuracy, ROC-AUC, Confusion Matrix  
   - Feature coefficients for interpretability  

4. **Neural Network Classifier (MLP)**  
   - 2â€“3 hidden layers with ReLU activation  
   - Dropout and BatchNorm for regularization  
   - Binary cross-entropy loss, Adam optimizer  
   - Compare performance with ElasticNet baseline  

5. **Model Interpretability**  
   - SHAP values to identify top predictors  
   - Compare insights from ElasticNet and Neural Network  
   - Discuss clinical relevance (e.g., Vitamin D, CRP, Lean Mass)

---

## ğŸ“ˆ Results

| Model          | Accuracy | ROC-AUC |
|----------------|---------|---------|
| ElasticNet     | xx.x%   | 0.xx    |
| Neural Network | xx.x%   | 0.xx    |

**Top predictors (from SHAP & ElasticNet):**


---

## ğŸ› ï¸ Technologies & Tools

- Python 3.x  
- scikit-learn (ElasticNet, preprocessing, K-Fold CV)  
- TensorFlow  
- pandas, numpy, matplotlib, seaborn (data handling & visualization)  
- SHAP (model interpretability)  
- Jupyter Notebooks for workflow organization  

---

## ğŸ—‚ï¸ Repository Structure

gallstone-prediction

â”œâ”€â”€ 01_exploratory_data_analysis.ipynb

â”œâ”€â”€ 02_data_preprocessing.ipynb

â”œâ”€â”€ 03_baseline_elasticnet.ipynb

â”œâ”€â”€ 04_neural_network_model.ipynb

â”œâ”€â”€ 05_model_interpretability.ipynb

â”‚â”€â”€ data/ # dataset placeholder

â”‚â”€â”€ src/ # optional helper scripts


â”‚â”€â”€ README.md